{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d05ceca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from relic import ReLIC\n",
    "from encoders import resnet18\n",
    "from aug import get_relic_aug_inference, get_relic_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea87b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec7dccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = get_relic_aug_inference()\n",
    "\n",
    "train_ds = torchvision.datasets.STL10(\"../data\",\n",
    "                                  split='train',\n",
    "                                  transform=transform,\n",
    "                                  download=True)\n",
    "val_ds = torchvision.datasets.STL10(\"../data\",\n",
    "                                  split='test',\n",
    "                                  transform=transform,\n",
    "                                  download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a900a33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 8000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a402d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"../models/relic_model.pth\")\n",
    "\n",
    "encoder = resnet18()\n",
    "model = ReLIC(encoder)\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda08697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_embs_targets(ds):\n",
    "    idx = 0\n",
    "    embs, targets = [], []\n",
    "    for idx, (image, target) in enumerate(tqdm(ds)):\n",
    "        with torch.no_grad():\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "            out = model.get_features(image)\n",
    "            features = out[0].cpu().detach().tolist()   \n",
    "            embs.append(features)\n",
    "            targets.append(target)\n",
    "    return embs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4788ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be92612f7b949d6ab57271abcaceac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a1620befdb412d8dc243401996e1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs, targets = get_embs_targets(train_ds)\n",
    "embs_val, targets_val = get_embs_targets(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a94989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = np.array(embs)\n",
    "labels = np.array(targets)\n",
    "embeddings_val = np.array(embs_val)\n",
    "labels_val = np.array(targets_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ddde94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 512)\n",
      "(5000,)\n",
      "(8000, 512)\n",
      "(8000,)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)\n",
    "print(labels.shape)\n",
    "print(embeddings_val.shape)\n",
    "print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2900a88-ee0d-4036-b7e7-742a05781a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 5000 5000\n",
      "test 8000 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wavelet/projects/relic/.env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/relic/.env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/relic/.env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/relic/.env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/relic/.env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.705125\n",
      "Confusion matrix: \n",
      " [[657  43  14   6   2   7   7   2  44  18]\n",
      " [ 18 580   0  71  18  30  10  70   3   0]\n",
      " [ 30   2 691   8   0   2   9   2  12  44]\n",
      " [  4  77   1 459  58  80  20  91   6   4]\n",
      " [  2  43   1  69 531  33  85  32   2   2]\n",
      " [  2  73   1 136  51 303 100 132   0   2]\n",
      " [  5   8   2  15  32  54 638  38   3   5]\n",
      " [  2  95   0  76  27  60  27 509   3   1]\n",
      " [ 47   3  12   7   0   3   0   1 696  31]\n",
      " [ 30   3  79  14   1   5  13   3  75 577]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       800\n",
      "           1       0.63      0.72      0.67       800\n",
      "           2       0.86      0.86      0.86       800\n",
      "           3       0.53      0.57      0.55       800\n",
      "           4       0.74      0.66      0.70       800\n",
      "           5       0.53      0.38      0.44       800\n",
      "           6       0.70      0.80      0.75       800\n",
      "           7       0.58      0.64      0.61       800\n",
      "           8       0.82      0.87      0.85       800\n",
      "           9       0.84      0.72      0.78       800\n",
      "\n",
      "    accuracy                           0.71      8000\n",
      "   macro avg       0.71      0.71      0.70      8000\n",
      "weighted avg       0.71      0.71      0.70      8000\n",
      "\n",
      "Classification report train: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       500\n",
      "           1       0.77      0.90      0.83       500\n",
      "           2       0.93      0.95      0.94       500\n",
      "           3       0.71      0.77      0.74       500\n",
      "           4       0.85      0.79      0.82       500\n",
      "           5       0.80      0.60      0.69       500\n",
      "           6       0.85      0.87      0.86       500\n",
      "           7       0.75      0.81      0.78       500\n",
      "           8       0.93      0.96      0.95       500\n",
      "           9       0.95      0.84      0.89       500\n",
      "\n",
      "    accuracy                           0.84      5000\n",
      "   macro avg       0.85      0.84      0.84      5000\n",
      "weighted avg       0.85      0.84      0.84      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X_train, X_test = embeddings, embeddings_val\n",
    "y_train, y_test = labels, labels_val\n",
    "\n",
    "print(\"train\", X_train.shape[0], len(y_train))\n",
    "print(\"test\", X_test.shape[0], len(y_test))\n",
    " \n",
    "clf = LogisticRegression(max_iter=100)\n",
    "clf = CalibratedClassifierCV(clf)\n",
    " \n",
    "clf.fit(X_train, y_train)\n",
    " \n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    " \n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Confusion matrix: \\n\", conf_matrix)\n",
    "print(\"Classification report: \\n\", class_report)\n",
    " \n",
    "y_pred_train = clf.predict(X_train)\n",
    "class_report = classification_report(y_train, y_pred_train)\n",
    "print(\"Classification report train: \\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e561248-9140-4bb7-9d07-bf138f19d42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
