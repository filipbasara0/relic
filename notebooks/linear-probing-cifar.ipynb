{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d05ceca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from relic import ReLIC\n",
    "from encoders import resnet18\n",
    "from aug import get_relic_aug_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea87b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec7dccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 32\n",
    "\n",
    "transform = get_relic_aug_inference()\n",
    "train_ds = torchvision.datasets.CIFAR10(\"../data/cifar\",\n",
    "                                  train=True,\n",
    "                                  transform=transform,\n",
    "                                  download=True)\n",
    "val_ds = torchvision.datasets.CIFAR10(\"../data/cifar\",\n",
    "                                  train=False,\n",
    "                                  transform=transform,\n",
    "                                  download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a900a33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a402d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"../models/relic_model.pth\")\n",
    "\n",
    "\n",
    "encoder = resnet18()\n",
    "model = ReLIC(encoder, mlp_in_dim=512)\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda08697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_embs_targets(ds):\n",
    "    idx = 0\n",
    "    embs, targets = [], []\n",
    "    for idx, (image, target) in enumerate(tqdm(ds)):\n",
    "        with torch.no_grad():\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "            out = model.get_features(image)\n",
    "            features = out[0].cpu().detach().tolist()   \n",
    "            embs.append(features)\n",
    "            targets.append(target)\n",
    "    return embs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4788ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6477fa6e564242baa56f8d70f428d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3664cd40f4164c2eb86b99cbd4e8efca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs, targets = get_embs_targets(train_ds)\n",
    "embs_val, targets_val = get_embs_targets(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a94989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = np.array(embs)\n",
    "labels = np.array(targets)\n",
    "embeddings_val = np.array(embs_val)\n",
    "labels_val = np.array(targets_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ddde94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 512)\n",
      "(50000,)\n",
      "(10000, 512)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)\n",
    "print(labels.shape)\n",
    "print(embeddings_val.shape)\n",
    "print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f8e6ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 50000 50000\n",
      "test 10000 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wavelet/projects/relic/.env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/relic/.env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/relic/.env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/relic/.env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/relic/.env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6493\n",
      "Confusion matrix: \n",
      " [[653  24  58  26  22  14  24  16 114  49]\n",
      " [ 18 749   8  15   8   5  21  10  49 117]\n",
      " [ 70   5 487  92  83  75 114  39  17  18]\n",
      " [ 20  16  56 459  64 170 127  52  14  22]\n",
      " [ 15   9  73  69 532  53 110 116  15   8]\n",
      " [  9   6  53 174  53 532  71  80   6  16]\n",
      " [ 11   7  26  51  27  36 813  11  10   8]\n",
      " [  8  14  20  44  58  77  15 735  10  19]\n",
      " [ 75  48  18  18   7   2   3   9 790  30]\n",
      " [ 30 113  11  22   5  12  14  23  27 743]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68      1000\n",
      "           1       0.76      0.75      0.75      1000\n",
      "           2       0.60      0.49      0.54      1000\n",
      "           3       0.47      0.46      0.47      1000\n",
      "           4       0.62      0.53      0.57      1000\n",
      "           5       0.55      0.53      0.54      1000\n",
      "           6       0.62      0.81      0.70      1000\n",
      "           7       0.67      0.73      0.70      1000\n",
      "           8       0.75      0.79      0.77      1000\n",
      "           9       0.72      0.74      0.73      1000\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.65      0.65      0.65     10000\n",
      "weighted avg       0.65      0.65      0.65     10000\n",
      "\n",
      "Classification report train: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73      5000\n",
      "           1       0.78      0.78      0.78      5000\n",
      "           2       0.61      0.54      0.57      5000\n",
      "           3       0.51      0.49      0.50      5000\n",
      "           4       0.67      0.58      0.62      5000\n",
      "           5       0.59      0.56      0.57      5000\n",
      "           6       0.64      0.81      0.71      5000\n",
      "           7       0.69      0.77      0.73      5000\n",
      "           8       0.78      0.83      0.80      5000\n",
      "           9       0.74      0.76      0.75      5000\n",
      "\n",
      "    accuracy                           0.68     50000\n",
      "   macro avg       0.68      0.68      0.68     50000\n",
      "weighted avg       0.68      0.68      0.68     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X_train, X_test = embeddings, embeddings_val\n",
    "y_train, y_test = labels, labels_val\n",
    "\n",
    "print(\"train\", X_train.shape[0], len(y_train))\n",
    "print(\"test\", X_test.shape[0], len(y_test))\n",
    " \n",
    "clf = LogisticRegression(max_iter=100)\n",
    "clf = CalibratedClassifierCV(clf)\n",
    " \n",
    "clf.fit(X_train, y_train)\n",
    " \n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    " \n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Confusion matrix: \\n\", conf_matrix)\n",
    "print(\"Classification report: \\n\", class_report)\n",
    " \n",
    "y_pred_train = clf.predict(X_train)\n",
    "class_report = classification_report(y_train, y_pred_train)\n",
    "print(\"Classification report train: \\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f687e-6954-49f8-9c01-a4961f2d0ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
